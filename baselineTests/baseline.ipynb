{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import everything\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, recall_score, accuracy_score, precision_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "#import algorithms\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "\n",
    "#import the variables\n",
    "CIC2017 = pd.read_csv('/Users/bryan/GitHub/capstonev2-6/dataprocessing/proc_csvfiles/CIC2017processed.csv')\n",
    "CIC2018 = pd.read_csv('/Users/bryan/GitHub/capstonev2-6/dataprocessing/proc_csvfiles/CIC2018processed.csv')\n",
    "HIKARI = pd.read_csv('/Users/bryan/GitHub/capstonev2-6/dataprocessing/proc_csvfiles/HIKARIprocessed.csv')\n",
    "\n",
    "CIC2017_attack = CIC2017['attack']\n",
    "CIC2018_attack = CIC2018['attack']\n",
    "HIKARI_attack = HIKARI['attack']\n",
    "\n",
    "del CIC2017['attack']\n",
    "del CIC2017['flow_pkts_per_sec']\n",
    "\n",
    "del CIC2018['attack']\n",
    "del CIC2018['flow_pkts_per_sec']\n",
    "\n",
    "del HIKARI['attack']\n",
    "del HIKARI['flow_pkts_per_sec']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-Layer Perceptron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Loop # 1\n",
      "In 53 iterations.\n",
      "Finished Loop # 2\n",
      "In 39 iterations.\n",
      "Finished Loop # 3\n",
      "In 55 iterations.\n",
      "Finished Loop # 4\n",
      "In 70 iterations.\n",
      "Finished Loop # 5\n",
      "In 82 iterations.\n",
      "Finished Loop # 6\n",
      "In 62 iterations.\n",
      "Finished Loop # 7\n",
      "In 52 iterations.\n",
      "Finished Loop # 8\n",
      "In 63 iterations.\n",
      "Finished Loop # 9\n",
      "In 62 iterations.\n",
      "Finished Loop # 10\n",
      "In 44 iterations.\n",
      "The following are MEDIANS: \n",
      " # Of Loops: 10 \n",
      "Accuracy: 0.9235647628610242 \n",
      "F1-Score: 0.9200038847055089 \n",
      "Recall: 0.9117251458765396 \n",
      "Precision 0.940379583252638 \n",
      "Iteration 58.5\n"
     ]
    }
   ],
   "source": [
    "#MLP for CIC2017\n",
    "\n",
    "x = CIC2017\n",
    "y = CIC2017_attack\n",
    "\n",
    "#split 60/40 : train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "model = MLPClassifier()\n",
    "f1list = []\n",
    "recallist=[]\n",
    "accuracylist = []\n",
    "precisionlist=[]\n",
    "iterlist = []\n",
    "loopno = 0\n",
    "\n",
    "for i in range(0,10):\n",
    "    loopno += 1\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    f1list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    recallist.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    accuracylist.append(accuracy_score(y_test, y_pred))\n",
    "    precisionlist.append(precision_score(y_test, y_pred, average='macro'))\n",
    "    print(\"Finished Loop #\",loopno)\n",
    "    n_iter = model.n_iter_\n",
    "    iterlist.append(n_iter)\n",
    "    print('In',n_iter,'iterations.')\n",
    "\n",
    "print(\n",
    "    'The following are MEDIANS:',\n",
    "    '\\n # Of Loops:',loopno,\n",
    "    '\\nAccuracy:',np.median(accuracylist),\n",
    "    '\\nF1-Score:',np.median(f1list),\n",
    "    '\\nRecall:',np.median(recallist),\n",
    "    '\\nPrecision:',np.median(precisionlist),\n",
    "    '\\nIteration:',np.median(iterlist)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Loop # 1\n",
      "In 31 iterations.\n",
      "Finished Loop # 2\n",
      "In 41 iterations.\n",
      "Finished Loop # 3\n",
      "In 50 iterations.\n",
      "Finished Loop # 4\n",
      "In 38 iterations.\n",
      "Finished Loop # 5\n",
      "In 32 iterations.\n",
      "Finished Loop # 6\n",
      "In 40 iterations.\n",
      "Finished Loop # 7\n",
      "In 43 iterations.\n",
      "Finished Loop # 8\n",
      "In 28 iterations.\n",
      "Finished Loop # 9\n",
      "In 39 iterations.\n",
      "Finished Loop # 10\n",
      "In 39 iterations.\n",
      "The following are MEDIANS: \n",
      " # Of Loops: 10 \n",
      "Accuracy: 0.9969784437952399 \n",
      "F1-Score: 0.9961947396992562 \n",
      "Recall: 0.9965696310001533 \n",
      "Precision: 0.9961719717056832 \n",
      "Iteration: 39.0\n"
     ]
    }
   ],
   "source": [
    "#MLP for CIC2018\n",
    "\n",
    "x = CIC2018 \n",
    "y = CIC2018_attack\n",
    "\n",
    "#split 60/40 : train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "model = MLPClassifier()\n",
    "f1list = []\n",
    "recallist=[]\n",
    "accuracylist = []\n",
    "precisionlist=[]\n",
    "iterlist = []\n",
    "loopno = 0\n",
    "\n",
    "for i in range(0,10):\n",
    "    loopno += 1\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    f1list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    recallist.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    accuracylist.append(accuracy_score(y_test, y_pred))\n",
    "    precisionlist.append(precision_score(y_test, y_pred, average='macro'))\n",
    "    print(\"Finished Loop #\",loopno)\n",
    "    n_iter = model.n_iter_\n",
    "    iterlist.append(n_iter)\n",
    "    print('In',n_iter,'iterations.')\n",
    "\n",
    "print(\n",
    "    'The following are MEDIANS:',\n",
    "    '\\n # Of Loops:',loopno,\n",
    "    '\\nAccuracy:',np.median(accuracylist),\n",
    "    '\\nF1-Score:',np.median(f1list),\n",
    "    '\\nRecall:',np.median(recallist),\n",
    "    '\\nPrecision:',np.median(precisionlist),\n",
    "    '\\nIteration:',np.median(iterlist)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Loop # 1\n",
      "In 76 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryan/opt/anaconda3/envs/bush/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Loop # 2\n",
      "In 84 iterations.\n",
      "Finished Loop # 3\n",
      "In 17 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryan/opt/anaconda3/envs/bush/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Loop # 4\n",
      "In 68 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryan/opt/anaconda3/envs/bush/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Loop # 5\n",
      "In 76 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryan/opt/anaconda3/envs/bush/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Loop # 6\n",
      "In 73 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryan/opt/anaconda3/envs/bush/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Loop # 7\n",
      "In 91 iterations.\n",
      "Finished Loop # 8\n",
      "In 77 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryan/opt/anaconda3/envs/bush/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Loop # 9\n",
      "In 71 iterations.\n",
      "Finished Loop # 10\n",
      "In 39 iterations.\n",
      "The following are MEDIANS: \n",
      " # Of Loops: 10 \n",
      "Accuracy: 0.9327966671469049 \n",
      "F1-Score: 0.48261500187903955 \n",
      "Recall: 0.5 \n",
      "Precision: 0.46639833357345245 \n",
      "Iteration: 74.5\n"
     ]
    }
   ],
   "source": [
    "#MLP for HIKARI\n",
    "\n",
    "x = HIKARI \n",
    "y = HIKARI_attack\n",
    "\n",
    "#split 60/40 : train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "model = MLPClassifier()\n",
    "f1list = []\n",
    "recallist=[]\n",
    "accuracylist = []\n",
    "precisionlist=[]\n",
    "iterlist = []\n",
    "loopno = 0\n",
    "\n",
    "for i in range(0,10):\n",
    "    loopno += 1\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    f1list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    recallist.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    accuracylist.append(accuracy_score(y_test, y_pred))\n",
    "    precisionlist.append(precision_score(y_test, y_pred, average='macro'))\n",
    "    print(\"Finished Loop #\",loopno)\n",
    "    n_iter = model.n_iter_\n",
    "    iterlist.append(n_iter)\n",
    "    print('In',n_iter,'iterations.')\n",
    "\n",
    "print(\n",
    "    'The following are MEDIANS:',\n",
    "    '\\n # Of Loops:',loopno,\n",
    "    '\\nAccuracy:',np.median(accuracylist),\n",
    "    '\\nF1-Score:',np.median(f1list),\n",
    "    '\\nRecall:',np.median(recallist),\n",
    "    '\\nPrecision:',np.median(precisionlist),\n",
    "    '\\nIteration:',np.median(iterlist)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9997342153446341 \n",
      "F1-Score: 0.9997293086578134 \n",
      "Recall: 0.9997617451166896 \n",
      "Precision 0.9996969900554775\n"
     ]
    }
   ],
   "source": [
    "#Random Forest CIC2017\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x = CIC2017 \n",
    "y = CIC2017_attack\n",
    "\n",
    "#split 70/30 : train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=50, bootstrap=True, random_state=1)\n",
    "\n",
    "f1list = []\n",
    "recallist=[]\n",
    "accuracylist = []\n",
    "precisionlist=[]\n",
    "loopno = 0\n",
    "for i in range(0,10):\n",
    "    loopno += 1\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    f1list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    recallist.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    accuracylist.append(accuracy_score(y_test, y_pred))\n",
    "    precisionlist.append(precision_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "print(\n",
    "    'Accuracy:',np.median(accuracylist),\n",
    "    '\\nF1-Score:',np.median(f1list),\n",
    "    '\\nRecall:',np.median(recallist),\n",
    "    '\\nPrecision',np.median(precisionlist)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9985980996461871 \n",
      "F1-Score: 0.9982318467524368 \n",
      "Recall: 0.9987333542671335 \n",
      "Precision 0.9977332673215813\n"
     ]
    }
   ],
   "source": [
    "#Random Forest CIC2018\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x = CIC2018\n",
    "y = CIC2018_attack\n",
    "\n",
    "#split 70/30 : train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=50, bootstrap=True, random_state=1)\n",
    "\n",
    "f1list = []\n",
    "recallist=[]\n",
    "accuracylist = []\n",
    "precisionlist=[]\n",
    "loopno = 0\n",
    "for i in range(0,10):\n",
    "    loopno += 1\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    f1list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    recallist.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    accuracylist.append(accuracy_score(y_test, y_pred))\n",
    "    precisionlist.append(precision_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "print(\n",
    "    'Accuracy:',np.median(accuracylist),\n",
    "    '\\nF1-Score:',np.median(f1list),\n",
    "    '\\nRecall:',np.median(recallist),\n",
    "    '\\nPrecision',np.median(precisionlist)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8892750804398982 \n",
      "F1-Score: 0.5334649147497212 \n",
      "Recall: 0.531369972543244 \n",
      "Precision 0.5363858777929995\n"
     ]
    }
   ],
   "source": [
    "#Random Forest HIKARI\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x = HIKARI\n",
    "y = HIKARI_attack\n",
    "\n",
    "#split 70/30 : train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=50, bootstrap=True, random_state=1)\n",
    "\n",
    "f1list = []\n",
    "recallist=[]\n",
    "accuracylist = []\n",
    "precisionlist=[]\n",
    "loopno = 0\n",
    "for i in range(0,10):\n",
    "    loopno += 1\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    f1list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    recallist.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    accuracylist.append(accuracy_score(y_test, y_pred))\n",
    "    precisionlist.append(precision_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "print(\n",
    "    'Accuracy:',np.median(accuracylist),\n",
    "    '\\nF1-Score:',np.median(f1list),\n",
    "    '\\nRecall:',np.median(recallist),\n",
    "    '\\nPrecision',np.median(precisionlist)\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Loop # 0\n",
      "Loops: 0 \n",
      "Accuracy: 0.7648691748863032 \n",
      "F1-Score: 0.7648602172489938 \n",
      "Recall: 0.778382873559885 \n",
      "Precision 0.7774782708805235\n"
     ]
    }
   ],
   "source": [
    "x = CIC2017 \n",
    "y = CIC2017_attack\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "# create a model \n",
    "model = SVC()\n",
    "\n",
    "f1list = []\n",
    "recallist=[]\n",
    "accuracylist = []\n",
    "precisionlist=[]\n",
    "loopno = 0\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "f1list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "recallist.append(recall_score(y_test, y_pred, average='macro'))\n",
    "accuracylist.append(accuracy_score(y_test, y_pred))\n",
    "precisionlist.append(precision_score(y_test, y_pred, average='macro'))\n",
    "print(\"Finished Loop #\",loopno)\n",
    "print(\n",
    "    'Loops:',loopno,\n",
    "    '\\nAccuracy:',np.median(accuracylist),\n",
    "    '\\nF1-Score:',np.median(f1list),\n",
    "    '\\nRecall:',np.median(recallist),\n",
    "    '\\nPrecision',np.median(precisionlist)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = CIC2018  \n",
    "y = CIC2018_attack\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "# create a model \n",
    "model = SVC()\n",
    "\n",
    "f1list = []\n",
    "recallist=[]\n",
    "accuracylist = []\n",
    "precisionlist=[]\n",
    "loopno = 0\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "f1list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "recallist.append(recall_score(y_test, y_pred, average='macro'))\n",
    "accuracylist.append(accuracy_score(y_test, y_pred))\n",
    "precisionlist.append(precision_score(y_test, y_pred, average='macro'))\n",
    "print(\"Finished Loop #\",loopno)\n",
    "print(\n",
    "    'Loops:',loopno,\n",
    "    '\\nAccuracy:',np.median(accuracylist),\n",
    "    '\\nF1-Score:',np.median(f1list),\n",
    "    '\\nRecall:',np.median(recallist),\n",
    "    '\\nPrecision',np.median(precisionlist)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9777777777777777 \n",
      "F1-Score: 0.9723551302498672 \n",
      "Recall: 0.9803921568627452 \n",
      "Precision 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "#CIC2017\n",
    "#importing necessary libraries \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.datasets import load_iris \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#loading the iris dataset \n",
    "iris = load_iris() \n",
    "\n",
    "data = CIC2017\n",
    "target = CIC2017_attack\n",
    "\n",
    "#extracting the features and labels \n",
    "X = iris.data \n",
    "y = iris.target\n",
    "\n",
    "#splitting the data into training and testing sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "#creating the model\n",
    "model = KNeighborsClassifier(n_neighbors=5) \n",
    "\n",
    "f1list = []\n",
    "recallist=[]\n",
    "accuracylist = []\n",
    "precisionlist=[]\n",
    "loopno = 0\n",
    "for i in range(0,10):\n",
    "    loopno += 1\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    f1list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    recallist.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    accuracylist.append(accuracy_score(y_test, y_pred))\n",
    "    precisionlist.append(precision_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "print(\n",
    "    'Accuracy:',np.median(accuracylist),\n",
    "    '\\nF1-Score:',np.median(f1list),\n",
    "    '\\nRecall:',np.median(recallist),\n",
    "    '\\nPrecision',np.median(precisionlist)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333333333333333 \n",
      "F1-Score: 0.9398762157382846 \n",
      "Recall: 0.9428571428571427 \n",
      "Precision 0.9380116959064327\n"
     ]
    }
   ],
   "source": [
    "#CIC2018\n",
    "#importing necessary libraries \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.datasets import load_iris \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#loading the iris dataset \n",
    "iris = load_iris() \n",
    "\n",
    "data = CIC2018\n",
    "target = CIC2018_attack\n",
    "\n",
    "#extracting the features and labels \n",
    "X = iris.data \n",
    "y = iris.target\n",
    "\n",
    "#splitting the data into training and testing sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "#creating the model\n",
    "model = KNeighborsClassifier(n_neighbors=5) \n",
    "\n",
    "f1list = []\n",
    "recallist=[]\n",
    "accuracylist = []\n",
    "precisionlist=[]\n",
    "loopno = 0\n",
    "for i in range(0,10):\n",
    "    loopno += 1\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    f1list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    recallist.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    accuracylist.append(accuracy_score(y_test, y_pred))\n",
    "    precisionlist.append(precision_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "print(\n",
    "    'Accuracy:',np.median(accuracylist),\n",
    "    '\\nF1-Score:',np.median(f1list),\n",
    "    '\\nRecall:',np.median(recallist),\n",
    "    '\\nPrecision',np.median(precisionlist)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9777777777777777 \n",
      "F1-Score: 0.9789819376026273 \n",
      "Recall: 0.9777777777777779 \n",
      "Precision 0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "#HIKARI\n",
    "#importing necessary libraries \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.datasets import load_iris \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#loading the iris dataset \n",
    "iris = load_iris() \n",
    "\n",
    "data = HIKARI\n",
    "target = HIKARI_attack\n",
    "\n",
    "#extracting the features and labels \n",
    "X = iris.data \n",
    "y = iris.target\n",
    "\n",
    "#splitting the data into training and testing sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "#creating the model\n",
    "model = KNeighborsClassifier(n_neighbors=5) \n",
    "\n",
    "f1list = []\n",
    "recallist=[]\n",
    "accuracylist = []\n",
    "precisionlist=[]\n",
    "loopno = 0\n",
    "for i in range(0,10):\n",
    "    loopno += 1\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    f1list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    recallist.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    accuracylist.append(accuracy_score(y_test, y_pred))\n",
    "    precisionlist.append(precision_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "print(\n",
    "    'Accuracy:',np.median(accuracylist),\n",
    "    '\\nF1-Score:',np.median(f1list),\n",
    "    '\\nRecall:',np.median(recallist),\n",
    "    '\\nPrecision',np.median(precisionlist)\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9996456204595121 \n",
      "F1-Score: 0.9996396156065475 \n",
      "Recall: 0.999655125565637 \n",
      "Precision 0.9996241349789742\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree CIC2017\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x = CIC2017 \n",
    "y = CIC2017_attack\n",
    "\n",
    "#split 70/30 : train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=50, bootstrap=True, random_state=1)\n",
    "f1list = []\n",
    "recallist=[]\n",
    "accuracylist = []\n",
    "precisionlist=[]\n",
    "for i in range(0,10):\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    f1list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    recallist.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    accuracylist.append(accuracy_score(y_test, y_pred))\n",
    "    precisionlist.append(precision_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "print(\n",
    "    'Accuracy:',np.median(accuracylist),\n",
    "    '\\nF1-Score:',np.median(f1list),\n",
    "    '\\nRecall:',np.median(recallist),\n",
    "    '\\nPrecision',np.median(precisionlist)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def scatter():\n",
    "    plt.scatter(range(1,10), f1list)\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('F1-Score')\n",
    "    plt.title('F1-Score by Model')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.998601278558554 \n",
      "F1-Score: 0.998238468986391 \n",
      "Recall: 0.9986959416360742 \n",
      "Precision 0.997783445475796\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree CIC2018\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x = CIC2018\n",
    "y = CIC2018_attack\n",
    "\n",
    "#split 70/30 : train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=50, bootstrap=True, random_state=1)\n",
    "f1list = []\n",
    "recallist=[]\n",
    "accuracylist = []\n",
    "precisionlist=[]\n",
    "for i in range(0,10):\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    f1list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    recallist.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    accuracylist.append(accuracy_score(y_test, y_pred))\n",
    "    precisionlist.append(precision_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "print(\n",
    "    'Accuracy:',np.median(accuracylist),\n",
    "    '\\nF1-Score:',np.median(f1list),\n",
    "    '\\nRecall:',np.median(recallist),\n",
    "    '\\nPrecision',np.median(precisionlist)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def scatter():\n",
    "    plt.scatter(range(1,10), f1list)\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('F1-Score')\n",
    "    plt.title('F1-Score by Model')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8903976372280651 \n",
      "F1-Score: 0.5380927318854495 \n",
      "Recall: 0.5359293293745455 \n",
      "Precision 0.5409376750988164\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree HIKARI\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x = HIKARI\n",
    "y = HIKARI_attack\n",
    "\n",
    "#split 70/30 : train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=50, bootstrap=True, random_state=1)\n",
    "f1list = []\n",
    "recallist=[]\n",
    "accuracylist = []\n",
    "precisionlist=[]\n",
    "for i in range(0,10):\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    f1list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    recallist.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    accuracylist.append(accuracy_score(y_test, y_pred))\n",
    "    precisionlist.append(precision_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "print(\n",
    "    'Accuracy:',np.median(accuracylist),\n",
    "    '\\nF1-Score:',np.median(f1list),\n",
    "    '\\nRecall:',np.median(recallist),\n",
    "    '\\nPrecision',np.median(precisionlist)\n",
    ")\n",
    "\n",
    "\n",
    "def scatter():\n",
    "    plt.scatter(range(1,10), f1list)\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('F1-Score')\n",
    "    plt.title('F1-Score by Model')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
