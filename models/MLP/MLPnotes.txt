Using Version 2 of the CSV files

model = MLPClassifier(hidden_layer_sizes=(12, 12, 12), max_iter=500,verbose=1)
    returned 
    score on test data:  0.6533581288892067
    [[665818  96566]
    [266914  19277]]

model = MLPClassifier(hidden_layer_sizes=(50, 40, 30), max_iter=500,verbose=1)
    returned
    score on test data:  0.7115695110030279
    [[593147 169237]
    [133204 152987]]
    read online that the first hidden layer should have nodes equal to or greater than features in the dataset.
    So i changed the first one to 50

hidden_layer_sizes=(50,55) - 50.579 Seconds
    returned   
    score on test data:  0.5889192475502467
    [[612462 149922]
    [281127   5064]]

hidden_layer_sizes=(50, 60, 70, 80, 100) - 91 seconds
    returned
    score on test data:  0.47247550246763464
    [[209262 553122]
    [    27 286164]]
 
model = MLPClassifier(hidden_layer_sizes=(50, 40, 30), max_iter=500,verbose=1)
    score on test data:  0.7076365543714088
    [[456940 305444]
    [  1121 285070]]
                precision    recall  f1-score   support

            0       1.00      0.60      0.75    762384
            1       0.48      1.00      0.65    286191

        accuracy                           0.71   1048575
    macro avg       0.74      0.80      0.70   1048575
    weighted avg       0.86      0.71      0.72   1048575

    score on test data:  0.48929165772596145
    [[226907 535477]
    [    39 286152]]
                precision    recall  f1-score   support

            0       1.00      0.30      0.46    762384
            1       0.35      1.00      0.52    286191
hidden_layer_sizes=(50, 40, 35, 30, 25)
    accuracy                           0.49   1048575
    macro avg       0.67      0.65      0.49   1048575
    weighted avg       0.82      0.49      0.47   1048575

hidden_layer_sizes=(50, 40, 35, 30)
    score on test data:  0.7442033235581623
    [[495841 266543]
    [  1679 284512]]
                precision    recall  f1-score   support

            0       1.00      0.65      0.79    762384
            1       0.52      0.99      0.68    286191

    accuracy                           0.74   1048575
    macro avg       0.76      0.82      0.73   1048575
    weighted avg       0.87      0.74      0.76   1048575

model = MLPClassifier(hidden_layer_sizes=(50, 40, 35, 30), max_iter=500,verbose=1, solver='adam', tol=.0003)
    score on test data:  0.6562668383282073
    [[402283 360101]
    [   329 285862]]
                precision    recall  f1-score   support

            0       1.00      0.53      0.69    762384
         x   1       0.44      1.00      0.61    286191

    accuracy                           0.66   1048575
    macro avg       0.72      0.76      0.65   1048575
    weighted avg       0.85      0.66      0.67   1048575

added batch_size= 8 - 16
    Return SHIIIITTT    

model = MLPClassifier(hidden_layer_sizes=(50, 40, 35, 30),verbose=1, solver='adam', tol=.0003)
    score on test data:  0.7073161194955058
    [[599263 163121]
    [143780 142411]]
                precision    recall  f1-score   support

            0       0.81      0.79      0.80    762384
            1       0.47      0.50      0.48    286191

    accuracy                           0.71   1048575
    macro avg       0.64      0.64      0.64   1048575
    weighted avg       0.71      0.71      0.71   1048575

model = MLPClassifier(hidden_layer_sizes=(50, 40, 35, 30),verbose=1, solver='adam', tol=.0001)
    score on test data:  0.47510001668931645
    [[212052 550332]
    [    65 286126]]
                precision    recall  f1-score   support

            0       1.00      0.28      0.44    762384
            1       0.34      1.00      0.51    286191

    accuracy                           0.48   1048575
    macro avg       0.67      0.64      0.47   1048575
    weighted avg       0.82      0.48      0.46   1048575

Same as above, but tol=.0002
    score on test data:  0.8159483108027561
    [[587094 175290]
    [ 17702 268489]]
                precision    recall  f1-score   support

            0       0.97      0.77      0.86    762384
            1       0.61      0.94      0.74    286191

    accuracy                           0.82   1048575
    macro avg       0.79      0.85      0.80   1048575
    weighted avg       0.87      0.82      0.83   1048575

Removed Solver = Adam
    score on test data:  0.672014877333524
    [[561738 200646]
    [143271 142920]]
                precision    recall  f1-score   support

            0       0.80      0.74      0.77    762384
            1       0.42      0.50      0.45    286191

        accuracy                           0.67   1048575
    macro avg       0.61      0.62      0.61   1048575
    weighted avg       0.69      0.67      0.68   1048575

model = MLPClassifier(hidden_layer_sizes=(50, 45, 37, 35),verbose=1, solver='adam', tol=.0002)
    score on test data:  0.4863848556374127
    [[223846 538538]
    [    26 286165]]
                precision    recall  f1-score   support

            0       1.00      0.29      0.45    762384
            1       0.35      1.00      0.52    286191

        accuracy                           0.49   1048575
    macro avg       0.67      0.65      0.48   1048575
    weighted avg       0.82      0.49      0.47   1048575

model = MLPClassifier(hidden_layer_sizes=(60, 50, 40, 35),verbose=1, solver='adam', tol=.0002)
    score on test data:  0.5475154376177193
    [[423370 339014]
    [135450 150741]]
                precision    recall  f1-score   support

            0       0.76      0.56      0.64    762384
            1       0.31      0.53      0.39    286191

        accuracy                           0.55   1048575
    macro avg       0.53      0.54      0.51   1048575
    weighted avg       0.63      0.55      0.57   1048575